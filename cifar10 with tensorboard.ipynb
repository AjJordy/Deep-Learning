{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jordy\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np # para computação numética menos intensiva\n",
    "import os # para criar pastas\n",
    "from matplotlib import pyplot as plt # para mostrar imagens\n",
    "import tensorflow as tf # para redes neurais\n",
    "from keras.datasets import cifar10\n",
    "import keras.utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos uma pasta para salvar o modelo\n",
    "if not os.path.exists('tmp'): # se a pasta não existir\n",
    "    os.makedirs('tmp')        # cria a pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "num_train, img_rows, img_cols, img_channels =  x_train.shape\n",
    "\n",
    "num_test, _, _, _ =  x_test.shape\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    fill_mode='nearest')\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo constantes\n",
    "lr = 0.0001       # taxa de aprendizado\n",
    "epochs = 500      # número de iterações de treino\n",
    "batch_size = 500  # qtd de imagens no mini-lote \n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/example/' # caminho do log para o tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():   \n",
    "    x = tf.placeholder(tf.float32, shape=[None, img_rows, img_cols, img_channels], name='x')\n",
    "    y = tf.placeholder(tf.float32, shape= [None,num_classes], name='y_input')\n",
    "    \n",
    "    input_layer = tf.reshape(x, [-1, img_rows, img_cols, img_channels])\n",
    "    # Convolutional Layer 1\n",
    "    conv1 = tf.layers.conv2d(inputs=x,\n",
    "                             filters=32,\n",
    "                             kernel_size=[8,8],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.selu,\n",
    "                             name=\"conv1\")\n",
    "\n",
    "    # Pooling Layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2,2], \n",
    "                                    strides=2,\n",
    "                                    name=\"pool1\")\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1,\n",
    "                             filters=32,\n",
    "                             kernel_size=[16, 16],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.selu,\n",
    "                             name=\"conv2\")\n",
    "        \n",
    "    \n",
    "    # Pooling Layer 2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2,2], \n",
    "                                    strides=2,\n",
    "                                    name=\"pool2\")\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2,\n",
    "                             filters=64,\n",
    "                             kernel_size=[32, 32],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.selu,\n",
    "                             name=\"conv3\")\n",
    "    # Pooling Layer 3\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2,\n",
    "                                    name=\"pool2\")\n",
    "    \n",
    "    \n",
    "     # Convolutional Layer 4\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3,\n",
    "                             filters=16,\n",
    "                             kernel_size=[8, 8],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.selu,\n",
    "                             name=\"conv4\")\n",
    "    \n",
    "    # Pooling Layer 5\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2,\n",
    "                                    name=\"pool4\")\n",
    "     \n",
    "    # Convolutional Layer 5\n",
    "    conv5 = tf.layers.conv2d(inputs=pool4,\n",
    "                             filters=32,\n",
    "                             kernel_size=[8, 8],\n",
    "                             padding=\"same\",\n",
    "                             activation=tf.nn.selu,\n",
    "                             name=\"conv5\")\n",
    "    # Pooling Layer 5\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2,\n",
    "                                    name=\"pool5\")\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.contrib.layers.flatten(pool5) \n",
    "    dense = tf.layers.dense(inputs=flat, \n",
    "                            units=1024, \n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    # Dropout\n",
    "    dropout = tf.layers.dropout(inputs=dense, \n",
    "                                rate=0.4)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs = dropout,\n",
    "                             units  = num_classes)\n",
    "\n",
    "    # Error Layer\n",
    "    with tf.name_scope('Error_layer'):\n",
    "        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits),\n",
    "                               name='error')\n",
    "        tf.summary.scalar('Cross_entropy', error) # para registrar a função custo\n",
    "\n",
    "    # Accuracy\n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar('Accuracy', accuracy) \n",
    "\n",
    "    # Optimizer\n",
    "    with tf.name_scope('Train_operation'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(error)\n",
    "\n",
    "    # Inicialyzer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Save model\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Visualization\n",
    "    summaries = tf.summary.merge_all() # funde todos os summaries em uma operação\n",
    "    file_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph()) # para escrever arquivos summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 0001 perda = 0.000046846\n",
      "Epoca: 0002 perda = 0.000045982\n",
      "Epoca: 0003 perda = 0.000046001\n",
      "Epoca: 0004 perda = 0.000045657\n",
      "Epoca: 0005 perda = 0.000045483\n",
      "Epoca: 0006 perda = 0.000045107\n",
      "Epoca: 0007 perda = 0.000044900\n",
      "Epoca: 0008 perda = 0.000044952\n",
      "Epoca: 0009 perda = 0.000044402\n",
      "Epoca: 0010 perda = 0.000043844\n",
      "Epoca: 0011 perda = 0.000042515\n",
      "Epoca: 0012 perda = 0.000043076\n",
      "Epoca: 0013 perda = 0.000042369\n",
      "Epoca: 0014 perda = 0.000041998\n",
      "Epoca: 0015 perda = 0.000041888\n",
      "Epoca: 0016 perda = 0.000040531\n",
      "Epoca: 0017 perda = 0.000039987\n",
      "Epoca: 0018 perda = 0.000040880\n",
      "Epoca: 0019 perda = 0.000040226\n",
      "Epoca: 0020 perda = 0.000038833\n",
      "Epoca: 0021 perda = 0.000040613\n",
      "Epoca: 0022 perda = 0.000040048\n",
      "Epoca: 0023 perda = 0.000039510\n",
      "Epoca: 0024 perda = 0.000037701\n",
      "Epoca: 0025 perda = 0.000039856\n",
      "Epoca: 0026 perda = 0.000037026\n",
      "Epoca: 0027 perda = 0.000038066\n",
      "Epoca: 0028 perda = 0.000037561\n",
      "Epoca: 0029 perda = 0.000037238\n",
      "Epoca: 0030 perda = 0.000038840\n",
      "Epoca: 0031 perda = 0.000039044\n",
      "Epoca: 0032 perda = 0.000038708\n",
      "Epoca: 0033 perda = 0.000037572\n",
      "Epoca: 0034 perda = 0.000037252\n",
      "Epoca: 0035 perda = 0.000037620\n",
      "Epoca: 0036 perda = 0.000037424\n",
      "Epoca: 0037 perda = 0.000037010\n",
      "Epoca: 0038 perda = 0.000036833\n",
      "Epoca: 0039 perda = 0.000036941\n",
      "Epoca: 0040 perda = 0.000035748\n",
      "Epoca: 0041 perda = 0.000036619\n",
      "Epoca: 0042 perda = 0.000036447\n",
      "Epoca: 0043 perda = 0.000036221\n",
      "Epoca: 0044 perda = 0.000035975\n",
      "Epoca: 0045 perda = 0.000035708\n",
      "Epoca: 0046 perda = 0.000036427\n",
      "Epoca: 0047 perda = 0.000034983\n",
      "Epoca: 0048 perda = 0.000036480\n",
      "Epoca: 0049 perda = 0.000035008\n",
      "Epoca: 0050 perda = 0.000037289\n",
      "Epoca: 0051 perda = 0.000036481\n",
      "Epoca: 0052 perda = 0.000036053\n",
      "Epoca: 0053 perda = 0.000037214\n",
      "Epoca: 0054 perda = 0.000035358\n",
      "Epoca: 0055 perda = 0.000035881\n",
      "Epoca: 0056 perda = 0.000033344\n",
      "Epoca: 0057 perda = 0.000034029\n",
      "Epoca: 0058 perda = 0.000034609\n",
      "Epoca: 0059 perda = 0.000033244\n",
      "Epoca: 0060 perda = 0.000034584\n",
      "Epoca: 0061 perda = 0.000034425\n",
      "Epoca: 0062 perda = 0.000034893\n",
      "Epoca: 0063 perda = 0.000034136\n",
      "Epoca: 0064 perda = 0.000033319\n",
      "Epoca: 0065 perda = 0.000033571\n",
      "Epoca: 0066 perda = 0.000034094\n",
      "Epoca: 0067 perda = 0.000035293\n",
      "Epoca: 0068 perda = 0.000034226\n",
      "Epoca: 0069 perda = 0.000033480\n",
      "Epoca: 0070 perda = 0.000032850\n",
      "Epoca: 0071 perda = 0.000033216\n",
      "Epoca: 0072 perda = 0.000033589\n",
      "Epoca: 0073 perda = 0.000031620\n",
      "Epoca: 0074 perda = 0.000034536\n",
      "Epoca: 0075 perda = 0.000032093\n",
      "Epoca: 0076 perda = 0.000034216\n",
      "Epoca: 0077 perda = 0.000034374\n",
      "Epoca: 0078 perda = 0.000033633\n",
      "Epoca: 0079 perda = 0.000032254\n",
      "Epoca: 0080 perda = 0.000033198\n",
      "Epoca: 0081 perda = 0.000031558\n",
      "Epoca: 0082 perda = 0.000032141\n",
      "Epoca: 0083 perda = 0.000031773\n",
      "Epoca: 0084 perda = 0.000034018\n",
      "Epoca: 0085 perda = 0.000032552\n",
      "Epoca: 0086 perda = 0.000032566\n",
      "Epoca: 0087 perda = 0.000032835\n",
      "Epoca: 0088 perda = 0.000032914\n",
      "Epoca: 0089 perda = 0.000032329\n",
      "Epoca: 0090 perda = 0.000032344\n",
      "Epoca: 0091 perda = 0.000032282\n",
      "Epoca: 0092 perda = 0.000032001\n",
      "Epoca: 0093 perda = 0.000031843\n",
      "Epoca: 0094 perda = 0.000031881\n",
      "Epoca: 0095 perda = 0.000032454\n",
      "Epoca: 0096 perda = 0.000031521\n",
      "Epoca: 0097 perda = 0.000031030\n",
      "Epoca: 0098 perda = 0.000031549\n",
      "Epoca: 0099 perda = 0.000033385\n",
      "Epoca: 0100 perda = 0.000032665\n",
      "Epoca: 0101 perda = 0.000032881\n",
      "Epoca: 0102 perda = 0.000031296\n",
      "Epoca: 0103 perda = 0.000030258\n",
      "Epoca: 0104 perda = 0.000031796\n",
      "Epoca: 0105 perda = 0.000031030\n",
      "Epoca: 0106 perda = 0.000032207\n",
      "Epoca: 0107 perda = 0.000032489\n",
      "Epoca: 0108 perda = 0.000032010\n",
      "Epoca: 0109 perda = 0.000031165\n",
      "Epoca: 0110 perda = 0.000030245\n",
      "Epoca: 0111 perda = 0.000031651\n",
      "Epoca: 0112 perda = 0.000031758\n",
      "Epoca: 0113 perda = 0.000030303\n",
      "Epoca: 0114 perda = 0.000030154\n",
      "Epoca: 0115 perda = 0.000030161\n",
      "Epoca: 0116 perda = 0.000030495\n",
      "Epoca: 0117 perda = 0.000031577\n",
      "Epoca: 0118 perda = 0.000032026\n",
      "Epoca: 0119 perda = 0.000030962\n",
      "Epoca: 0120 perda = 0.000031339\n",
      "Epoca: 0121 perda = 0.000029820\n",
      "Epoca: 0122 perda = 0.000031063\n",
      "Epoca: 0123 perda = 0.000031909\n",
      "Epoca: 0124 perda = 0.000031664\n",
      "Epoca: 0125 perda = 0.000030112\n",
      "Epoca: 0126 perda = 0.000031980\n",
      "Epoca: 0127 perda = 0.000029909\n",
      "Epoca: 0128 perda = 0.000032354\n",
      "Epoca: 0129 perda = 0.000030775\n",
      "Epoca: 0130 perda = 0.000030700\n",
      "Epoca: 0131 perda = 0.000031057\n",
      "Epoca: 0132 perda = 0.000029791\n",
      "Epoca: 0133 perda = 0.000031290\n",
      "Epoca: 0134 perda = 0.000031299\n",
      "Epoca: 0135 perda = 0.000030365\n",
      "Epoca: 0136 perda = 0.000028698\n",
      "Epoca: 0137 perda = 0.000029940\n",
      "Epoca: 0138 perda = 0.000031525\n",
      "Epoca: 0139 perda = 0.000029593\n",
      "Epoca: 0140 perda = 0.000030339\n",
      "Epoca: 0141 perda = 0.000031575\n",
      "Epoca: 0142 perda = 0.000029833\n",
      "Epoca: 0143 perda = 0.000029875\n",
      "Epoca: 0144 perda = 0.000029670\n",
      "Epoca: 0145 perda = 0.000030849\n",
      "Epoca: 0146 perda = 0.000030496\n",
      "Epoca: 0147 perda = 0.000030100\n",
      "Epoca: 0148 perda = 0.000029779\n",
      "Epoca: 0149 perda = 0.000030748\n",
      "Epoca: 0150 perda = 0.000029370\n",
      "Epoca: 0151 perda = 0.000030141\n",
      "Epoca: 0152 perda = 0.000029718\n",
      "Epoca: 0153 perda = 0.000030378\n",
      "Epoca: 0154 perda = 0.000029951\n",
      "Epoca: 0155 perda = 0.000029745\n",
      "Epoca: 0156 perda = 0.000029422\n",
      "Epoca: 0157 perda = 0.000030103\n",
      "Epoca: 0158 perda = 0.000031150\n",
      "Epoca: 0159 perda = 0.000030192\n",
      "Epoca: 0160 perda = 0.000028686\n",
      "Epoca: 0161 perda = 0.000031477\n",
      "Epoca: 0162 perda = 0.000030989\n",
      "Epoca: 0163 perda = 0.000029442\n",
      "Epoca: 0164 perda = 0.000029505\n",
      "Epoca: 0165 perda = 0.000028085\n",
      "Epoca: 0166 perda = 0.000029283\n",
      "Epoca: 0167 perda = 0.000030559\n",
      "Epoca: 0168 perda = 0.000028979\n",
      "Epoca: 0169 perda = 0.000028728\n",
      "Epoca: 0170 perda = 0.000029648\n",
      "Epoca: 0171 perda = 0.000029402\n",
      "Epoca: 0172 perda = 0.000028034\n",
      "Epoca: 0173 perda = 0.000031795\n",
      "Epoca: 0174 perda = 0.000028192\n",
      "Epoca: 0175 perda = 0.000029512\n",
      "Epoca: 0176 perda = 0.000029234\n",
      "Epoca: 0177 perda = 0.000028905\n",
      "Epoca: 0178 perda = 0.000027751\n",
      "Epoca: 0179 perda = 0.000028775\n",
      "Epoca: 0180 perda = 0.000028417\n",
      "Epoca: 0181 perda = 0.000029577\n",
      "Epoca: 0182 perda = 0.000027296\n",
      "Epoca: 0183 perda = 0.000029670\n",
      "Epoca: 0184 perda = 0.000027674\n",
      "Epoca: 0185 perda = 0.000030183\n",
      "Epoca: 0186 perda = 0.000028858\n",
      "Epoca: 0187 perda = 0.000028918\n",
      "Epoca: 0188 perda = 0.000029596\n",
      "Epoca: 0189 perda = 0.000027023\n",
      "Epoca: 0190 perda = 0.000029509\n",
      "Epoca: 0191 perda = 0.000030286\n",
      "Epoca: 0192 perda = 0.000026168\n",
      "Epoca: 0193 perda = 0.000027093\n",
      "Epoca: 0194 perda = 0.000029193\n",
      "Epoca: 0195 perda = 0.000028175\n",
      "Epoca: 0196 perda = 0.000028806\n",
      "Epoca: 0197 perda = 0.000028374\n",
      "Epoca: 0198 perda = 0.000031082\n",
      "Epoca: 0199 perda = 0.000027852\n",
      "Epoca: 0200 perda = 0.000027118\n",
      "Epoca: 0201 perda = 0.000029002\n",
      "Epoca: 0202 perda = 0.000029906\n",
      "Epoca: 0203 perda = 0.000026663\n",
      "Epoca: 0204 perda = 0.000028839\n",
      "Epoca: 0205 perda = 0.000027873\n",
      "Epoca: 0206 perda = 0.000027989\n",
      "Epoca: 0207 perda = 0.000027251\n",
      "Epoca: 0208 perda = 0.000027783\n",
      "Epoca: 0209 perda = 0.000029438\n",
      "Epoca: 0210 perda = 0.000027296\n",
      "Epoca: 0211 perda = 0.000026264\n",
      "Epoca: 0212 perda = 0.000026766\n",
      "Epoca: 0213 perda = 0.000026575\n",
      "Epoca: 0214 perda = 0.000027027\n",
      "Epoca: 0215 perda = 0.000026567\n",
      "Epoca: 0216 perda = 0.000026330\n",
      "Epoca: 0217 perda = 0.000028883\n",
      "Epoca: 0218 perda = 0.000027073\n",
      "Epoca: 0219 perda = 0.000025644\n",
      "Epoca: 0220 perda = 0.000028227\n",
      "Epoca: 0221 perda = 0.000027371\n",
      "Epoca: 0222 perda = 0.000027204\n",
      "Epoca: 0223 perda = 0.000027163\n",
      "Epoca: 0224 perda = 0.000028202\n",
      "Epoca: 0225 perda = 0.000026490\n",
      "Epoca: 0226 perda = 0.000026182\n",
      "Epoca: 0227 perda = 0.000028977\n",
      "Epoca: 0228 perda = 0.000027117\n",
      "Epoca: 0229 perda = 0.000025744\n",
      "Epoca: 0230 perda = 0.000025478\n",
      "Epoca: 0231 perda = 0.000026997\n",
      "Epoca: 0232 perda = 0.000028259\n",
      "Epoca: 0233 perda = 0.000026671\n",
      "Epoca: 0234 perda = 0.000028215\n",
      "Epoca: 0235 perda = 0.000026176\n",
      "Epoca: 0236 perda = 0.000028704\n",
      "Epoca: 0237 perda = 0.000025204\n",
      "Epoca: 0238 perda = 0.000027217\n",
      "Epoca: 0239 perda = 0.000026819\n",
      "Epoca: 0240 perda = 0.000026584\n",
      "Epoca: 0241 perda = 0.000026273\n",
      "Epoca: 0242 perda = 0.000028172\n",
      "Epoca: 0243 perda = 0.000025509\n",
      "Epoca: 0244 perda = 0.000026370\n",
      "Epoca: 0245 perda = 0.000025360\n",
      "Epoca: 0246 perda = 0.000025319\n",
      "Epoca: 0247 perda = 0.000026142\n",
      "Epoca: 0248 perda = 0.000025579\n",
      "Epoca: 0249 perda = 0.000026853\n",
      "Epoca: 0250 perda = 0.000025164\n",
      "Epoca: 0251 perda = 0.000027083\n",
      "Epoca: 0252 perda = 0.000025849\n",
      "Epoca: 0253 perda = 0.000026263\n",
      "Epoca: 0254 perda = 0.000027416\n",
      "Epoca: 0255 perda = 0.000025273\n",
      "Epoca: 0256 perda = 0.000026390\n",
      "Epoca: 0257 perda = 0.000027337\n",
      "Epoca: 0258 perda = 0.000026386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 0259 perda = 0.000027250\n",
      "Epoca: 0260 perda = 0.000026987\n",
      "Epoca: 0261 perda = 0.000026817\n",
      "Epoca: 0262 perda = 0.000025493\n",
      "Epoca: 0263 perda = 0.000026664\n",
      "Epoca: 0264 perda = 0.000026411\n",
      "Epoca: 0265 perda = 0.000029278\n",
      "Epoca: 0266 perda = 0.000023411\n",
      "Epoca: 0267 perda = 0.000025916\n",
      "Epoca: 0268 perda = 0.000025551\n",
      "Epoca: 0269 perda = 0.000027600\n",
      "Epoca: 0270 perda = 0.000026835\n",
      "Epoca: 0271 perda = 0.000027124\n",
      "Epoca: 0272 perda = 0.000026793\n",
      "Epoca: 0273 perda = 0.000026393\n",
      "Epoca: 0274 perda = 0.000026728\n",
      "Epoca: 0275 perda = 0.000024606\n",
      "Epoca: 0276 perda = 0.000025985\n",
      "Epoca: 0277 perda = 0.000026980\n",
      "Epoca: 0278 perda = 0.000024539\n",
      "Epoca: 0279 perda = 0.000024826\n",
      "Epoca: 0280 perda = 0.000027166\n",
      "Epoca: 0281 perda = 0.000025442\n",
      "Epoca: 0282 perda = 0.000025123\n",
      "Epoca: 0283 perda = 0.000026854\n",
      "Epoca: 0284 perda = 0.000026887\n",
      "Epoca: 0285 perda = 0.000026033\n",
      "Epoca: 0286 perda = 0.000025532\n",
      "Epoca: 0287 perda = 0.000025195\n",
      "Epoca: 0288 perda = 0.000027135\n",
      "Epoca: 0289 perda = 0.000024601\n",
      "Epoca: 0290 perda = 0.000025770\n",
      "Epoca: 0291 perda = 0.000025798\n",
      "Epoca: 0292 perda = 0.000026445\n",
      "Epoca: 0293 perda = 0.000024090\n",
      "Epoca: 0294 perda = 0.000025520\n",
      "Epoca: 0295 perda = 0.000026166\n",
      "Epoca: 0296 perda = 0.000025958\n",
      "Epoca: 0297 perda = 0.000023863\n",
      "Epoca: 0298 perda = 0.000024360\n",
      "Epoca: 0299 perda = 0.000026514\n",
      "Epoca: 0300 perda = 0.000026093\n",
      "Epoca: 0301 perda = 0.000025121\n",
      "Epoca: 0302 perda = 0.000025467\n",
      "Epoca: 0303 perda = 0.000025417\n",
      "Epoca: 0304 perda = 0.000025515\n",
      "Epoca: 0305 perda = 0.000023959\n",
      "Epoca: 0306 perda = 0.000025913\n",
      "Epoca: 0307 perda = 0.000026273\n",
      "Epoca: 0308 perda = 0.000027133\n",
      "Epoca: 0309 perda = 0.000026249\n",
      "Epoca: 0310 perda = 0.000023955\n",
      "Epoca: 0311 perda = 0.000026453\n",
      "Epoca: 0312 perda = 0.000026819\n",
      "Epoca: 0313 perda = 0.000023778\n",
      "Epoca: 0314 perda = 0.000025408\n",
      "Epoca: 0315 perda = 0.000024002\n",
      "Epoca: 0316 perda = 0.000025153\n",
      "Epoca: 0317 perda = 0.000024699\n",
      "Epoca: 0318 perda = 0.000025457\n",
      "Epoca: 0319 perda = 0.000026290\n",
      "Epoca: 0320 perda = 0.000026323\n",
      "Epoca: 0321 perda = 0.000026685\n",
      "Epoca: 0322 perda = 0.000027301\n",
      "Epoca: 0323 perda = 0.000024277\n",
      "Epoca: 0324 perda = 0.000026323\n",
      "Epoca: 0325 perda = 0.000024348\n",
      "Epoca: 0326 perda = 0.000025316\n",
      "Epoca: 0327 perda = 0.000024195\n",
      "Epoca: 0328 perda = 0.000025944\n",
      "Epoca: 0329 perda = 0.000024294\n",
      "Epoca: 0330 perda = 0.000025389\n",
      "Epoca: 0331 perda = 0.000023405\n",
      "Epoca: 0332 perda = 0.000023741\n",
      "Epoca: 0333 perda = 0.000024868\n",
      "Epoca: 0334 perda = 0.000024523\n",
      "Epoca: 0335 perda = 0.000024872\n",
      "Epoca: 0336 perda = 0.000025651\n",
      "Epoca: 0337 perda = 0.000024632\n",
      "Epoca: 0338 perda = 0.000024295\n",
      "Epoca: 0339 perda = 0.000024929\n",
      "Epoca: 0340 perda = 0.000023721\n",
      "Epoca: 0341 perda = 0.000024571\n",
      "Epoca: 0342 perda = 0.000025894\n",
      "Epoca: 0343 perda = 0.000024657\n",
      "Epoca: 0344 perda = 0.000025358\n",
      "Epoca: 0345 perda = 0.000024736\n",
      "Epoca: 0346 perda = 0.000024689\n",
      "Epoca: 0347 perda = 0.000024662\n",
      "Epoca: 0348 perda = 0.000023816\n",
      "Epoca: 0349 perda = 0.000024973\n",
      "Epoca: 0350 perda = 0.000026899\n",
      "Epoca: 0351 perda = 0.000023611\n",
      "Epoca: 0352 perda = 0.000027128\n",
      "Epoca: 0353 perda = 0.000025177\n",
      "Epoca: 0354 perda = 0.000026175\n",
      "Epoca: 0355 perda = 0.000026636\n",
      "Epoca: 0356 perda = 0.000025575\n",
      "Epoca: 0357 perda = 0.000026003\n",
      "Epoca: 0358 perda = 0.000025639\n",
      "Epoca: 0359 perda = 0.000024788\n",
      "Epoca: 0360 perda = 0.000024900\n",
      "Epoca: 0361 perda = 0.000024656\n",
      "Epoca: 0362 perda = 0.000023683\n",
      "Epoca: 0363 perda = 0.000024654\n",
      "Epoca: 0364 perda = 0.000023901\n",
      "Epoca: 0365 perda = 0.000025060\n",
      "Epoca: 0366 perda = 0.000024975\n",
      "Epoca: 0367 perda = 0.000024059\n",
      "Epoca: 0368 perda = 0.000025907\n",
      "Epoca: 0369 perda = 0.000024716\n",
      "Epoca: 0370 perda = 0.000025141\n",
      "Epoca: 0371 perda = 0.000024794\n",
      "Epoca: 0372 perda = 0.000023882\n",
      "Epoca: 0373 perda = 0.000023780\n",
      "Epoca: 0374 perda = 0.000025393\n",
      "Epoca: 0375 perda = 0.000023606\n",
      "Epoca: 0376 perda = 0.000024253\n",
      "Epoca: 0377 perda = 0.000023866\n",
      "Epoca: 0378 perda = 0.000025247\n",
      "Epoca: 0379 perda = 0.000022264\n",
      "Epoca: 0380 perda = 0.000023243\n",
      "Epoca: 0381 perda = 0.000025953\n",
      "Epoca: 0382 perda = 0.000025195\n",
      "Epoca: 0383 perda = 0.000025070\n",
      "Epoca: 0384 perda = 0.000023713\n",
      "Epoca: 0385 perda = 0.000024015\n",
      "Epoca: 0386 perda = 0.000024108\n",
      "Epoca: 0387 perda = 0.000023426\n",
      "Epoca: 0388 perda = 0.000022969\n",
      "Epoca: 0389 perda = 0.000024250\n",
      "Epoca: 0390 perda = 0.000024339\n",
      "Epoca: 0391 perda = 0.000025001\n",
      "Epoca: 0392 perda = 0.000023613\n",
      "Epoca: 0393 perda = 0.000023988\n",
      "Epoca: 0394 perda = 0.000024160\n",
      "Epoca: 0395 perda = 0.000023821\n",
      "Epoca: 0396 perda = 0.000024189\n",
      "Epoca: 0397 perda = 0.000024529\n",
      "Epoca: 0398 perda = 0.000023591\n",
      "Epoca: 0399 perda = 0.000021540\n",
      "Epoca: 0400 perda = 0.000024534\n",
      "Epoca: 0401 perda = 0.000022974\n",
      "Epoca: 0402 perda = 0.000023338\n",
      "Epoca: 0403 perda = 0.000022751\n",
      "Epoca: 0404 perda = 0.000024198\n",
      "Epoca: 0405 perda = 0.000023104\n",
      "Epoca: 0406 perda = 0.000024136\n",
      "Epoca: 0407 perda = 0.000024966\n",
      "Epoca: 0408 perda = 0.000024612\n",
      "Epoca: 0409 perda = 0.000021266\n",
      "Epoca: 0410 perda = 0.000023814\n",
      "Epoca: 0411 perda = 0.000022185\n",
      "Epoca: 0412 perda = 0.000022698\n",
      "Epoca: 0413 perda = 0.000023504\n",
      "Epoca: 0414 perda = 0.000024250\n",
      "Epoca: 0415 perda = 0.000025073\n",
      "Epoca: 0416 perda = 0.000022918\n",
      "Epoca: 0417 perda = 0.000022801\n",
      "Epoca: 0418 perda = 0.000023051\n",
      "Epoca: 0419 perda = 0.000024302\n",
      "Epoca: 0420 perda = 0.000021573\n",
      "Epoca: 0421 perda = 0.000023057\n",
      "Epoca: 0422 perda = 0.000024505\n",
      "Epoca: 0423 perda = 0.000024235\n",
      "Epoca: 0424 perda = 0.000023821\n",
      "Epoca: 0425 perda = 0.000024572\n",
      "Epoca: 0426 perda = 0.000024089\n",
      "Epoca: 0427 perda = 0.000022370\n",
      "Epoca: 0428 perda = 0.000024807\n",
      "Epoca: 0429 perda = 0.000023224\n",
      "Epoca: 0430 perda = 0.000024204\n",
      "Epoca: 0431 perda = 0.000025270\n",
      "Epoca: 0432 perda = 0.000022527\n",
      "Epoca: 0433 perda = 0.000024256\n",
      "Epoca: 0434 perda = 0.000022477\n",
      "Epoca: 0435 perda = 0.000024380\n",
      "Epoca: 0436 perda = 0.000023643\n",
      "Epoca: 0437 perda = 0.000023049\n",
      "Epoca: 0438 perda = 0.000023378\n",
      "Epoca: 0439 perda = 0.000022339\n",
      "Epoca: 0440 perda = 0.000025081\n",
      "Epoca: 0441 perda = 0.000023770\n",
      "Epoca: 0442 perda = 0.000023492\n",
      "Epoca: 0443 perda = 0.000023084\n",
      "Epoca: 0444 perda = 0.000025069\n",
      "Epoca: 0445 perda = 0.000023067\n",
      "Epoca: 0446 perda = 0.000024283\n",
      "Epoca: 0447 perda = 0.000022090\n",
      "Epoca: 0448 perda = 0.000025467\n",
      "Epoca: 0449 perda = 0.000021706\n",
      "Epoca: 0450 perda = 0.000024227\n",
      "Epoca: 0451 perda = 0.000024112\n",
      "Epoca: 0452 perda = 0.000023588\n",
      "Epoca: 0453 perda = 0.000023305\n",
      "Epoca: 0454 perda = 0.000022528\n",
      "Epoca: 0455 perda = 0.000023820\n",
      "Epoca: 0456 perda = 0.000021451\n",
      "Epoca: 0457 perda = 0.000022615\n",
      "Epoca: 0458 perda = 0.000020660\n",
      "Epoca: 0459 perda = 0.000023081\n",
      "Epoca: 0460 perda = 0.000023258\n",
      "Epoca: 0461 perda = 0.000023641\n",
      "Epoca: 0462 perda = 0.000022604\n",
      "Epoca: 0463 perda = 0.000023336\n",
      "Epoca: 0464 perda = 0.000023322\n",
      "Epoca: 0465 perda = 0.000021501\n",
      "Epoca: 0466 perda = 0.000023875\n",
      "Epoca: 0467 perda = 0.000022149\n",
      "Epoca: 0468 perda = 0.000022462\n",
      "Epoca: 0469 perda = 0.000022907\n",
      "Epoca: 0470 perda = 0.000022696\n",
      "Epoca: 0471 perda = 0.000022821\n",
      "Epoca: 0472 perda = 0.000022756\n",
      "Epoca: 0473 perda = 0.000021852\n",
      "Epoca: 0474 perda = 0.000022262\n",
      "Epoca: 0475 perda = 0.000022095\n",
      "Epoca: 0476 perda = 0.000020715\n",
      "Epoca: 0477 perda = 0.000022291\n",
      "Epoca: 0478 perda = 0.000022300\n",
      "Epoca: 0479 perda = 0.000023774\n",
      "Epoca: 0480 perda = 0.000022640\n",
      "Epoca: 0481 perda = 0.000024467\n",
      "Epoca: 0482 perda = 0.000022854\n",
      "Epoca: 0483 perda = 0.000023446\n",
      "Epoca: 0484 perda = 0.000023108\n",
      "Epoca: 0485 perda = 0.000022313\n",
      "Epoca: 0486 perda = 0.000023694\n",
      "Epoca: 0487 perda = 0.000021817\n",
      "Epoca: 0488 perda = 0.000022308\n",
      "Epoca: 0489 perda = 0.000022344\n",
      "Epoca: 0490 perda = 0.000022722\n",
      "Epoca: 0491 perda = 0.000021907\n",
      "Epoca: 0492 perda = 0.000024500\n",
      "Epoca: 0493 perda = 0.000023046\n",
      "Epoca: 0494 perda = 0.000021887\n",
      "Epoca: 0495 perda = 0.000022047\n",
      "Epoca: 0496 perda = 0.000023703\n",
      "Epoca: 0497 perda = 0.000022568\n",
      "Epoca: 0498 perda = 0.000023419\n",
      "Epoca: 0499 perda = 0.000022516\n",
      "Epoca: 0500 perda = 0.000022145\n",
      "Epoca: 0501 perda = 0.000024354\n",
      "Optimization Finished!\n",
      "Taxa de acerto:  55.830%\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tensorflow_logs \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "# abrimos a sessão tf\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #init.run() # iniciamos as variáveis\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    # loop de treinamento\n",
    "    for step in range(epochs+1):\n",
    "        avg_cost = 0.\n",
    "        # Number of images in the training-set.\n",
    "        num_images = len(y_train)\n",
    "\n",
    "        # Create a random index.\n",
    "        idx = np.random.choice(num_images,\n",
    "                               size=batch_size,\n",
    "                               replace=False)\n",
    "\n",
    "        # Use the random index to select random images and labels.      \n",
    "        x_batch = x_train[idx, :, :, :]\n",
    "        y_batch = y_train[idx, :]\n",
    "\n",
    "        # cria um feed_dict\n",
    "        feed_dict = {x: x_batch, y: y_batch}\n",
    "        c, _ = sess.run([error, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / num_images\n",
    "        \n",
    "        print('Epoca:', '%04d' % (step + 1), 'perda =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    score =  sess.run(accuracy, feed_dict={x: x_test, y: y_test}) * 100\n",
    "    print(\"Taxa de acerto: % .3f%%\" % score)\n",
    "        \n",
    "    # Calculate accuracy\n",
    "    #print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test}))\n",
    "\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close() # fechamos o nó de escrever no disco."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
